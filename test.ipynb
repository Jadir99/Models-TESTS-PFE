{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb42125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8ef4bc2c8e471c96e74c7d64891d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "import pandas as pd\n",
    "\n",
    "# ==============================\n",
    "# Load GLiNER model (multilingual v2.1 - higher accuracy)\n",
    "# ==============================\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_multi-v2.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5909442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# French and English CV text\n",
    "# ==============================\n",
    "# French CV example\n",
    "text_fr = \"\"\"\n",
    "Mohammed JADIR\n",
    "\n",
    "√âtudiant Ing√©nieur en Data Science & Intelligence Artificielle\n",
    "\n",
    "üìû +212 6 82 84 65 80\n",
    "üìß mohamad.jadir2018@gmail.com\n",
    "\n",
    "üîó GitHub : github.com/Jadir99\n",
    "üîó LinkedIn : mohammed-jadir\n",
    "üåê Portfolio : jadir-mohammed.com\n",
    "\n",
    "üéì FORMATION\n",
    "\n",
    "Dipl√¥me d‚ÄôIng√©nieur ‚Äì Data Science, Big Data & Intelligence Artificielle\n",
    "√âcole Nationale Sup√©rieure de l‚ÄôIntelligence Artificielle et Sciences des Donn√©es (ENSIASD), Taroudant\n",
    "2023 ‚Äì Pr√©sent\n",
    "\n",
    "Dipl√¥me Universitaire de Technologie (DUT) ‚Äì G√©nie Informatique\n",
    "√âcole Sup√©rieure de Technologie (EST), Universit√© Cadi Ayyad, Safi\n",
    "2021 ‚Äì 2023\n",
    "\n",
    "üíº EXP√âRIENCE PROFESSIONNELLE\n",
    "Stagiaire Data Science ‚Äì Banque Centrale Populaire (Stage PFA)\n",
    "\n",
    "Juillet 2025 ‚Äì Septembre 2025\n",
    "\n",
    "D√©veloppement d‚Äôun mod√®le hybride CamemBERT + Random Forest pour la classification automatique des r√©clamations clients.\n",
    "\n",
    "Conception de dashboards interactifs avec Power BI pour l‚Äôaide √† la d√©cision.\n",
    "\n",
    "Analyse et traitement des donn√©es avec Pandas et PostgreSQL.\n",
    "\n",
    "D√©veloppement et d√©ploiement d‚ÄôAPI avec Flask.\n",
    "\n",
    "Stagiaire Data Science ‚Äì YaneCode\n",
    "\n",
    "Juillet 2024 ‚Äì Ao√ªt 2024\n",
    "\n",
    "D√©veloppement d‚Äôune plateforme e-learning intelligente int√©grant un syst√®me de recommandation bas√© sur l‚ÄôIA.\n",
    "\n",
    "Utilisation de Laravel, Flask, TensorFlow, Gemini LLM, Scikit-learn, NumPy et Pandas.\n",
    "\n",
    "Conception de l‚Äôarchitecture backend et entra√Ænement des mod√®les de recommandation.\n",
    "\n",
    "Int√©gration des algorithmes IA dans l‚Äôapplication web.\n",
    "\n",
    "üöÄ PROJETS\n",
    "SmartCourseQA ‚Äì Chatbot Intelligent & G√©n√©rateur de Quiz\n",
    "\n",
    "github.com/Jadir99/SmartCourseQA\n",
    "\n",
    "D√©veloppement d‚Äôune application RAG hybride (FAISS, BM25, GPT-4o-mini, multilingual-e5-large).\n",
    "\n",
    "Chatbot acad√©mique, g√©n√©ration automatique de QCM et syst√®me d‚Äô√©valuation.\n",
    "\n",
    "Backend d√©velopp√© avec Flask.\n",
    "\n",
    "Syst√®me de Questions-R√©ponses sur Documents PDF\n",
    "\n",
    "github.com/Jadir99/RAG-Based-Document-Question-Answering-System\n",
    "\n",
    "Impl√©mentation d‚Äôun syst√®me RAG bas√© sur SentenceTransformers, FAISS et GPT-4o-mini.\n",
    "\n",
    "Interface interactive avec affichage des r√©f√©rences de pages et score de confiance.\n",
    "\n",
    "D√©veloppement avec Flask.\n",
    "\n",
    "AZUL-AI ‚Äì Plateforme Touristique IA\n",
    "\n",
    "azulaimaroc.com\n",
    "\n",
    "Transformation de l‚Äôexp√©rience touristique au Maroc via l‚ÄôIA g√©n√©rative.\n",
    "\n",
    "Int√©gration de Gemini LLM, backend en Flask et API consomm√©e en JavaScript.\n",
    "\n",
    "Application de Visualisation ‚Äì League of Legends\n",
    "\n",
    "github.com/Jadir99/league-of-legend-prediction-win\n",
    "\n",
    "Analyse et visualisation des donn√©es joueurs avec SQL, Django, Pandas, NumPy et Chart.js.\n",
    "\n",
    "Pr√©sentation des performances et statistiques avanc√©es.\n",
    "\n",
    "Amazon Product Sentiment Analysis\n",
    "\n",
    "github.com/Jadir99/Sentiment-analysis-from-product-reviews\n",
    "\n",
    "Scraping automatis√© via Selenium.\n",
    "\n",
    "Analyse de sentiments avec RoBERTa.\n",
    "\n",
    "Visualisations avec Matplotlib, Seaborn et WordCloud.\n",
    "\n",
    "üõ† COMP√âTENCES TECHNIQUES\n",
    "üîπ Machine Learning / IA\n",
    "\n",
    "Python, TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, NLP, Power BI\n",
    "\n",
    "üîπ D√©veloppement & Outils\n",
    "\n",
    "Laravel, Flask, Django, Hadoop, MapReduce, Java, Git, GitHub, Docker, Linux, n8n\n",
    "\n",
    "üîπ Bases de donn√©es\n",
    "\n",
    "MySQL, SQLite, PostgreSQL, MongoDB\n",
    "\n",
    "üìú CERTIFICATIONS\n",
    "\n",
    "365 Data Science ‚Äì Deep Learning with TensorFlow 2\n",
    "\n",
    "Oracle Cloud Infrastructure 2025 Certified Generative AI Professional\n",
    "\n",
    "CCNAv7 ‚Äì Introduction to Networks\n",
    "\n",
    "üåç LANGUES\n",
    "\n",
    "Arabe : Langue maternelle\n",
    "\n",
    "Fran√ßais : Interm√©diaire\n",
    "\n",
    "Anglais : Interm√©diaire\n",
    "\n",
    "üéØ ACTIVIT√âS PARASCOLAIRES\n",
    "\n",
    "Membre principal ‚Äì Google Developer Group (GDG), Campus Universiapolis (2024‚Äì2025)\n",
    "\n",
    "Pr√©sident ‚Äì Club Nakama (Culture asiatique) (2023‚Äì2024)\n",
    "\n",
    "Pr√©sident ‚Äì Chess Club (2022‚Äì2023)\n",
    "\"\"\"\n",
    "\n",
    "# Or English CV example\n",
    "text_en = \"\"\"\n",
    "# Mohammed JADIR\n",
    "\n",
    "# Engineering Student in Data Science & Artificial Intelligence\n",
    "\n",
    "# üìû +212 6 82 84 65 80\n",
    "# üìß mohamad.jadir2018@gmail.com\n",
    "\n",
    "# üîó GitHub: github.com/Jadir99\n",
    "# üîó LinkedIn: mohammed-jadir\n",
    "# üåê Portfolio: jadir-mohammed.com\n",
    "\n",
    "# üéì EDUCATION\n",
    "\n",
    "# Engineering Degree in Data Science, Big Data & Artificial Intelligence\n",
    "# National School of Artificial Intelligence and Data Science (ENSIASD), Taroudant\n",
    "# 2023 ‚Äì Present\n",
    "\n",
    "# University Diploma of Technology (DUT) in Computer Engineering\n",
    "# Higher School of Technology (EST), Cadi Ayyad University, Safi\n",
    "# 2021 ‚Äì 2023\n",
    "\n",
    "# üíº PROFESSIONAL EXPERIENCE\n",
    "# Data Science Intern ‚Äì Banque Centrale Populaire (PFA Internship)\n",
    "\n",
    "# July 2025 ‚Äì September 2025\n",
    "\n",
    "# Developed a hybrid CamemBERT + Random Forest model for automatic customer complaint classification.\n",
    "\n",
    "# Designed interactive dashboards using Power BI to support decision-making.\n",
    "\n",
    "# Processed and analyzed data using Pandas and PostgreSQL.\n",
    "\n",
    "# Built and deployed APIs using Flask.\n",
    "\n",
    "# Data Science Intern ‚Äì YaneCode\n",
    "\n",
    "# July 2024 ‚Äì August 2024\n",
    "\n",
    "# Developed an intelligent e-learning platform integrating an AI-based recommendation system.\n",
    "\n",
    "# Used Laravel, Flask, TensorFlow, Gemini LLM, Scikit-learn, NumPy, and Pandas.\n",
    "\n",
    "# Designed backend architecture and trained recommendation models.\n",
    "\n",
    "# Integrated AI algorithms into the web application.\n",
    "\n",
    "# üöÄ PROJECTS\n",
    "# SmartCourseQA ‚Äì Intelligent Chatbot & Quiz Generator\n",
    "\n",
    "# github.com/Jadir99/SmartCourseQA\n",
    "\n",
    "# Developed a hybrid RAG application (FAISS, BM25, GPT-4o-mini, multilingual-e5-large).\n",
    "\n",
    "# Academic chatbot with automatic MCQ generation and evaluation system.\n",
    "\n",
    "# Backend built with Flask.\n",
    "\n",
    "# RAG-Based Document Question Answering System\n",
    "\n",
    "# github.com/Jadir99/RAG-Based-Document-Question-Answering-System\n",
    "\n",
    "# Implemented a RAG-based QA system using SentenceTransformers, FAISS, and GPT-4o-mini.\n",
    "\n",
    "# Interactive interface with page references and confidence scores.\n",
    "\n",
    "# Developed using Flask.\n",
    "\n",
    "# AZUL-AI ‚Äì AI-Powered Tourism Platform\n",
    "\n",
    "# azulaimaroc.com\n",
    "\n",
    "# Enhanced the tourism experience in Morocco using generative AI.\n",
    "\n",
    "# Integrated Gemini LLM, Flask backend, and JavaScript API consumption.\n",
    "\n",
    "# League of Legends Data Visualization Application\n",
    "\n",
    "# github.com/Jadir99/league-of-legend-prediction-win\n",
    "\n",
    "# Data analysis and visualization using SQL, Django, Pandas, NumPy, and Chart.js.\n",
    "\n",
    "# Analyzed player statistics and performance metrics.\n",
    "\n",
    "# Amazon Product Sentiment Analysis\n",
    "\n",
    "# github.com/Jadir99/Sentiment-analysis-from-product-reviews\n",
    "\n",
    "# Automated product review extraction using Selenium.\n",
    "\n",
    "# Sentiment analysis using RoBERTa.\n",
    "\n",
    "# Data visualization with Matplotlib, Seaborn, and WordCloud.\n",
    "\n",
    "# üõ† TECHNICAL SKILLS\n",
    "# Machine Learning & AI\n",
    "\n",
    "# Python, TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, NLP, Power BI\n",
    "\n",
    "# Development & Tools\n",
    "\n",
    "# Laravel, Flask, Django, Hadoop, MapReduce, Java, Git, GitHub, Docker, Linux, n8n\n",
    "\n",
    "# Databases\n",
    "\n",
    "# MySQL, SQLite, PostgreSQL, MongoDB\n",
    "\n",
    "# üìú CERTIFICATIONS\n",
    "\n",
    "# 365 Data Science ‚Äì Deep Learning with TensorFlow 2\n",
    "\n",
    "# Oracle Cloud Infrastructure 2025 ‚Äì Certified Generative AI Professional\n",
    "\n",
    "# CCNAv7 ‚Äì Introduction to Networks\n",
    "\n",
    "# üåç LANGUAGES\n",
    "\n",
    "# Arabic: Native\n",
    "\n",
    "# French: Intermediate\n",
    "\n",
    "# English: Intermediate\n",
    "\n",
    "# üéØ EXTRACURRICULAR ACTIVITIES\n",
    "\n",
    "# Core Member ‚Äì Google Developer Group (GDG), Universiapolis Campus (2024‚Äì2025)\n",
    "\n",
    "# President ‚Äì Nakama Club (Asian Culture Club) (2023‚Äì2024)\n",
    "\n",
    "# President ‚Äì Chess Club (2022‚Äì2023)\n",
    "# \"\"\"\n",
    "# text_en = \"\"\"Skilled in Python and SQL.\n",
    "# Graduated from ENSA Safi.\"\"\"\n",
    "# text_fr = \"\"\"Comp√©tent en Python et SQL.  \n",
    "# Dipl√¥m√© de l'ENSA Safi.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f52f6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ==============================\n",
    "# Labels for IT resumes (French & English)\n",
    "# ==============================\n",
    "labels_fr = [\n",
    "    \"Comp√©tence technique / Hard Skill (Python, TensorFlow, PyTorch, SQL, Docker, Machine Learning, Deep Learning, NLP, Power BI, Scikit-learn, Flask, Django, Laravel, Git, Linux, MongoDB, PostgreSQL, MySQL, NumPy, Pandas)\",\n",
    "    \"Comp√©tence humaine / Soft Skill (Leadership, Communication, Travail en √©quipe, Cr√©ativit√©, Adaptabilit√©, R√©solution de probl√®mes, Esprit critique, Gestion du temps)\",\n",
    "    \"Formation / Education (Dipl√¥me d'Ing√©nieur, Master, Licence, DUT, Universit√©, √âcole Nationale, √âcole Sup√©rieure, √âtudes, Baccalaur√©at, ENSIASD, EST)\",\n",
    "    \"Exp√©rience professionnelle / Experience (Stage, Stagiaire, Emploi, CDD, CDI, Mission, Consultant, D√©veloppeur, Ing√©nieur, Alternance)\",\n",
    "    \"Projet / Project (Projet, Application, Plateforme, Syst√®me, GitHub, Chatbot, API, Dashboard, Mod√®le IA, RAG, QA, Quiz)\",\n",
    "    \"Certification / Certificate (Certificat, Certification, Dipl√¥me professionnel, Oracle, CCNA, Coursera, LinkedIn Learning, Google, 365 Data Science)\",\n",
    "    \"Langue / Language (Arabe, Fran√ßais, Anglais, Espagnol, Berb√®re, Langue maternelle, Bilingue, Courant, Interm√©diaire, D√©butant)\",\n",
    "    \"Activit√© extra-scolaire / Extracurricular Activity (Club, Pr√©sident, Vice-Pr√©sident, Membre, Association, B√©n√©volat, Organisation, √âv√©nement, GDG, Google Developer Group)\",\n",
    "    \"Entreprise / Company (Entreprise, Soci√©t√©, Organisation, Start-up, Multinationale, Banque, Agence, Cabinet, Groupe, Banque Centrale Populaire, YaneCode)\"\n",
    "]\n",
    "\n",
    "labels_en = [\n",
    "    \"Hard Skill (Python, TensorFlow, PyTorch, SQL, Docker, Machine Learning, Deep Learning, NLP, Power BI, Scikit-learn, Flask, Django, Laravel, Git, Linux, MongoDB, PostgreSQL, MySQL, NumPy, Pandas)\",\n",
    "    \"Soft Skill (Leadership, Communication, Teamwork, Creativity, Adaptability, Problem-solving, Critical thinking, Time management)\",\n",
    "    \"Education (Engineering Degree, Master, Bachelor, University, National School, Higher School, Studies, Diploma, Baccalaureate, ENSIASD, EST)\",\n",
    "    \"Experience (Intern, Internship, Full-time, Part-time, Consultant, Developer, Engineer, Freelance, Mission, Contract)\",\n",
    "    \"Project (Project, Application, Platform, System, GitHub, Chatbot, API, Dashboard, AI Model, Web App, RAG, QA, Quiz Generator)\",\n",
    "    \"Certification (Certificate, Professional Certificate, Oracle, CCNA, Coursera, LinkedIn Learning, Google, Microsoft, AWS, 365 Data Science)\",\n",
    "    \"Language (Arabic, French, English, Spanish, Amazigh, Native, Bilingual, Fluent, Intermediate, Beginner)\",\n",
    "    \"Extracurricular Activity (Club, President, Vice-President, Member, Association, Volunteering, Organization, Event, GDG, Google Developer Group)\",\n",
    "    \"Company (Company, Organization, Start-up, Multinational, Bank, Agency, Firm, Group, Corporation, Banque Centrale Populaire, YaneCode)\"\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# Known hard skill keywords (for boosting)\n",
    "# ==============================\n",
    "HARD_SKILLS_KEYWORDS = [\n",
    "    \"Python\", \"TensorFlow\", \"PyTorch\", \"Scikit-learn\", \"Pandas\", \"NumPy\",\n",
    "    \"Matplotlib\", \"Seaborn\", \"NLP\", \"Power BI\", \"Flask\", \"Django\", \"Laravel\",\n",
    "    \"Git\", \"GitHub\", \"Docker\", \"Linux\", \"MySQL\", \"SQLite\", \"PostgreSQL\",\n",
    "    \"MongoDB\", \"Hadoop\", \"MapReduce\", \"Java\", \"SQL\", \"FAISS\", \"BM25\",\n",
    "    \"Machine Learning\", \"Deep Learning\", \"CamemBERT\", \"Random Forest\",\n",
    "    \"SentenceTransformers\", \"RoBERTa\", \"Selenium\", \"JavaScript\", \"Chart.js\",\n",
    "    \"n8n\", \"Gemini LLM\", \"GPT-4o-mini\", \"RAG\", \"FastAPI\", \"REST API\",\n",
    "    \"Jupyter\", \"Keras\", \"XGBoost\", \"LightGBM\", \"Spark\", \"Kafka\",\n",
    "]\n",
    "\n",
    "CERT_KEYWORDS = [\n",
    "    \"365 Data Science\", \"Deep Learning with TensorFlow 2\",\n",
    "    \"Oracle Cloud Infrastructure 2025 Certified Generative AI Professional\",\n",
    "    \"Oracle Cloud Infrastructure 2025\", \"CCNAv7\", \"CCNAv7 ‚Äì Introduction to Networks\",\n",
    "    \"Introduction to Networks\",\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# Text preprocessing: strip comment markers, emojis, normalize chars\n",
    "# ==============================\n",
    "def preprocess_text(text):\n",
    "    # FIX: Strip Python '# ' comment prefixes from every line\n",
    "    lines = text.split('\\n')\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        s = line.lstrip()\n",
    "        if s.startswith('# '):\n",
    "            # Remove leading spaces + '# '\n",
    "            line = line[:len(line) - len(s)] + s[2:]\n",
    "        elif s == '#':\n",
    "            line = ''\n",
    "        cleaned.append(line)\n",
    "    text = '\\n'.join(cleaned)\n",
    "\n",
    "    # Remove emoji / decorative unicode\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        u\"\\U00002700-\\U000027BF\"\n",
    "        u\"\\U0001F900-\\U0001F9FF\"\n",
    "        u\"\\U00002500-\\U00002BEF\"\n",
    "        u\"\\U0001FA00-\\U0001FA6F\"\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"\n",
    "        u\"\\U00002300-\\U000023FF\"  # misc technical\n",
    "        \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "    text = emoji_pattern.sub(' ', text)\n",
    "\n",
    "    # Normalize dashes (en/em dash ‚Üí hyphen)\n",
    "    text = text.replace('‚Äì', '-').replace('‚Äî', '-')\n",
    "    # Normalize bullets/special chars\n",
    "    text = re.sub(r'[üîπüî∏‚óè‚ñ™‚ñ∏‚ñ∫‚Ä¢‚ó¶]', '', text)\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r' {2,}', ' ', text)\n",
    "    # Normalize multiple blank lines\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "# ==============================\n",
    "# Smart chunking: split by section first, then by word count\n",
    "# Section headers are preserved at the top of each chunk.\n",
    "# chunk_size=150 words keeps us safely under the 384-token limit.\n",
    "# ==============================\n",
    "SECTION_HEADERS = re.compile(\n",
    "    r'(?m)^(FORMATION|EDUCATION|EXPERIENCE|EXP√âRIENCE|PROJET|PROJECT|'\n",
    "    r'CERTIFICATION|LANGUE|LANGUAGE|ACTIVIT√â|EXTRACURRICULAR|COMP√âTENCE|'\n",
    "    r'SKILL|ENTREPRISE|COMPANY|ABOUT|SUMMARY|PROFIL)\\b.*$',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def chunk_text(text, chunk_size=150, overlap=30):\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    all_words = []\n",
    "    for para in paragraphs:\n",
    "        words = para.split()\n",
    "        if words:\n",
    "            all_words.extend(words)\n",
    "            all_words.append('|||')  # section boundary token\n",
    "\n",
    "    flat = [w for w in all_words if w != '|||']\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(flat):\n",
    "        chunk = flat[i: i + chunk_size]\n",
    "        chunks.append(' '.join(chunk))\n",
    "        i += chunk_size - overlap\n",
    "    return [c for c in chunks if c.strip()]\n",
    "\n",
    "# ==============================\n",
    "# Split comma-separated hard skills spans into individual items\n",
    "# e.g. \"Python, TensorFlow, PyTorch\" -> [\"Python\", \"TensorFlow\", \"PyTorch\"]\n",
    "# ==============================\n",
    "def split_skill_spans(items, label):\n",
    "    if 'Hard Skill' not in label and 'Comp√©tence technique' not in label:\n",
    "        return items\n",
    "    expanded = []\n",
    "    for text, score in items:\n",
    "        parts = [p.strip() for p in re.split(r'[,/]', text) if p.strip()]\n",
    "        if len(parts) > 1:\n",
    "            for part in parts:\n",
    "                if len(part) > 1:\n",
    "                    expanded.append((part, score))\n",
    "        else:\n",
    "            expanded.append((text, score))\n",
    "    return expanded\n",
    "\n",
    "# ==============================\n",
    "# Remove entities fully contained within a longer entity (NMS)\n",
    "# ==============================\n",
    "def remove_substrings(items):\n",
    "    texts = [t for t, _ in items]\n",
    "    kept = []\n",
    "    for i, (t, s) in enumerate(items):\n",
    "        is_sub = any(\n",
    "            t.lower() != texts[j].lower() and t.lower() in texts[j].lower()\n",
    "            for j in range(len(texts)) if i != j\n",
    "        )\n",
    "        if not is_sub:\n",
    "            kept.append((t, s))\n",
    "    return kept\n",
    "\n",
    "# ==============================\n",
    "# Entity extraction\n",
    "# ==============================\n",
    "def extract_entities(text, labels, model, threshold=0.2):\n",
    "    text = preprocess_text(text)\n",
    "    chunks = chunk_text(text)\n",
    "    all_entities = []\n",
    "    for chunk in chunks:\n",
    "        if chunk.strip():\n",
    "            ents = model.predict_entities(chunk, labels, threshold=threshold)\n",
    "            all_entities.extend(ents)\n",
    "\n",
    "    results = {label: [] for label in labels}\n",
    "    for ent in all_entities:\n",
    "        results[ent['label']].append((ent['text'], ent['score']))\n",
    "    return results\n",
    "\n",
    "# ==============================\n",
    "# Merge: split skill spans, case-insensitive dedup, sort by score\n",
    "# ==============================\n",
    "def merge_entities(results, min_length=2):\n",
    "    merged = {}\n",
    "    for label, items in results.items():\n",
    "        items = split_skill_spans(items, label)\n",
    "        unique_texts = {}\n",
    "        for text, score in items:\n",
    "            key = text.strip().lower()\n",
    "            if len(key) < min_length:\n",
    "                continue\n",
    "            if key in unique_texts:\n",
    "                if score > unique_texts[key][1]:\n",
    "                    unique_texts[key] = (text.strip(), score)\n",
    "            else:\n",
    "                unique_texts[key] = (text.strip(), score)\n",
    "        sorted_items = sorted(unique_texts.values(), key=lambda x: -x[1])\n",
    "        merged[label] = remove_substrings(sorted_items)\n",
    "    return merged\n",
    "\n",
    "# ==============================\n",
    "# Boost soft skills (keyword scan)\n",
    "# ==============================\n",
    "def boost_soft_skills(results, text, soft_keywords, lang=\"FR\"):\n",
    "    for keyword in soft_keywords:\n",
    "        for label in results:\n",
    "            if 'Soft Skill' in label:\n",
    "                existing = [e[0].lower() for e in results[label]]\n",
    "                if keyword.lower() not in existing and keyword.lower() in text.lower():\n",
    "                    results[label].append((keyword, 0.95))\n",
    "    return results\n",
    "\n",
    "# ==============================\n",
    "# Boost hard skills (keyword scan for known tech terms)\n",
    "# ==============================\n",
    "def boost_hard_skills(results, text, hard_keywords):\n",
    "    for label in results:\n",
    "        if 'Hard Skill' in label or 'Comp√©tence technique' in label:\n",
    "            existing = {e[0].lower() for e in results[label]}\n",
    "            for kw in hard_keywords:\n",
    "                if kw.lower() not in existing and kw.lower() in text.lower():\n",
    "                    results[label].append((kw, 0.90))\n",
    "    return results\n",
    "\n",
    "# ==============================\n",
    "# Boost certifications (keyword scan)\n",
    "# ==============================\n",
    "def boost_certifications(results, text, cert_keywords):\n",
    "    for label in results:\n",
    "        if 'Certification' in label or 'Certificate' in label:\n",
    "            existing = {e[0].lower() for e in results[label]}\n",
    "            for kw in cert_keywords:\n",
    "                if kw.lower() not in existing and kw.lower() in text.lower():\n",
    "                    results[label].append((kw, 0.90))\n",
    "    return results\n",
    "\n",
    "# ==============================\n",
    "# Display\n",
    "# ==============================\n",
    "def display_results(results, labels, lang=\"FR\"):\n",
    "    print(f\"\\n{'='*65}\\nEXTRACTED ENTITIES ({lang})\\n{'='*65}\")\n",
    "    total = 0\n",
    "    for label in labels:\n",
    "        items = results[label]\n",
    "        if items:\n",
    "            short_label = label.split('(')[0].strip()\n",
    "            print(f\"\\n  [{short_label}]\")\n",
    "            for text, score in items:\n",
    "                bar = '‚ñà' * int(score * 10) + '‚ñë' * (10 - int(score * 10))\n",
    "                print(f\"    ‚Ä¢ {text:<42} {bar} {score:.2f}\")\n",
    "            total += len(items)\n",
    "    found = sum(1 for v in results.values() if v)\n",
    "    print(f\"\\n  Total entities : {total}\")\n",
    "    print(f\"  Categories filled: {found}/{len(labels)}\")\n",
    "\n",
    "# ==============================\n",
    "# Side-by-side comparison\n",
    "# ==============================\n",
    "def compare_results(results_fr, results_en, labels_fr, labels_en):\n",
    "    rows = []\n",
    "    for fl, el in zip(labels_fr, labels_en):\n",
    "        fi = [e[0] for e in results_fr[fl]]\n",
    "        ei = [e[0] for e in results_en[el]]\n",
    "        rows.append({\n",
    "            'Category': el.split('(')[0].strip(),\n",
    "            'French': ', '.join(fi) if fi else '‚Äî',\n",
    "            'English': ', '.join(ei) if ei else '‚Äî',\n",
    "            'Match': '‚úì' if fi and ei else '‚úó'\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5a83d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "EXTRACTED ENTITIES (FR)\n",
      "=================================================================\n",
      "\n",
      "  [Comp√©tence technique / Hard Skill]\n",
      "    ‚Ä¢ Pr√©sident                                  ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.44\n",
      "    ‚Ä¢ Stagiaire                                  ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.40\n",
      "    ‚Ä¢ Python                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ TensorFlow                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ PyTorch                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Scikit-learn                               ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Pandas                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ NumPy                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Matplotlib                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Seaborn                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ NLP                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Power BI                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Flask                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Django                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Laravel                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Git                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ GitHub                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Docker                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Linux                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ MySQL                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ SQLite                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ PostgreSQL                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ MongoDB                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Hadoop                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ MapReduce                                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Java                                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ SQL                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ FAISS                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ BM25                                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Machine Learning                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Deep Learning                              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ CamemBERT                                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Random Forest                              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ SentenceTransformers                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ RoBERTa                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Selenium                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ JavaScript                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Chart.js                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ n8n                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Gemini LLM                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ GPT-4o-mini                                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ RAG                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "\n",
      "  [Formation / Education]\n",
      "    ‚Ä¢ √âcole Nationale Sup√©rieure de l‚ÄôIntelligence Artificielle et Sciences des Donn√©es ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.75\n",
      "    ‚Ä¢ Flask                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 0.66\n",
      "    ‚Ä¢ PostgreSQL                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 0.63\n",
      "    ‚Ä¢ Power BI                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 0.63\n",
      "    ‚Ä¢ Pandas                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.58\n",
      "    ‚Ä¢ CamemBERT + Random Forest                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.51\n",
      "    ‚Ä¢ GitHub                                     ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.46\n",
      "    ‚Ä¢ Ing√©nieur en Data Science & Intelligence Artificielle ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.38\n",
      "    ‚Ä¢ Certified Generative AI Professional       ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.30\n",
      "    ‚Ä¢ Quiz                                       ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.30\n",
      "    ‚Ä¢ QCM                                        ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.29\n",
      "    ‚Ä¢ API                                        ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.28\n",
      "    ‚Ä¢ DUT                                        ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.26\n",
      "    ‚Ä¢ Dipl√¥me Universitaire de Technologie       ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.26\n",
      "    ‚Ä¢ Dipl√¥me d‚ÄôIng√©nieur                        ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.25\n",
      "    ‚Ä¢ IA                                         ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.23\n",
      "    ‚Ä¢ TensorFlow 2                               ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.22\n",
      "    ‚Ä¢ Gemini LLM                                 ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.20\n",
      "\n",
      "  [Exp√©rience professionnelle / Experience]\n",
      "    ‚Ä¢ Stagiaire                                  ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.37\n",
      "    ‚Ä¢ Stage                                      ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.34\n",
      "    ‚Ä¢ syst√®me de recommandation                  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.28\n",
      "\n",
      "  [Projet / Project]\n",
      "    ‚Ä¢ Gemini LLM                                 ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.42\n",
      "    ‚Ä¢ Flask                                      ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.33\n",
      "    ‚Ä¢ RAG                                        ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.32\n",
      "    ‚Ä¢ API                                        ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.31\n",
      "    ‚Ä¢ SentenceTransformers                       ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.28\n",
      "    ‚Ä¢ GPT-4o-mini                                ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.27\n",
      "    ‚Ä¢ Pandas                                     ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.24\n",
      "    ‚Ä¢ FAISS                                      ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.24\n",
      "    ‚Ä¢ PostgreSQL                                 ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.23\n",
      "    ‚Ä¢ BM25                                       ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.23\n",
      "    ‚Ä¢ multilingual-e5-large                      ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.21\n",
      "\n",
      "  [Certification / Certificate]\n",
      "    ‚Ä¢ CCNAv7                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.54\n",
      "    ‚Ä¢ API                                        ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.48\n",
      "    ‚Ä¢ plateforme e-learning intelligente         ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.39\n",
      "    ‚Ä¢ Power BI                                   ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.33\n",
      "    ‚Ä¢ Certified Generative AI Professional       ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.32\n",
      "    ‚Ä¢ Oracle Cloud Infrastructure 2025           ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.28\n",
      "    ‚Ä¢ 365 Data Science - Deep Learning           ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.22\n",
      "    ‚Ä¢ Selenium                                   ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.21\n",
      "    ‚Ä¢ MapReduce                                  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.21\n",
      "    ‚Ä¢ TensorFlow                                 ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.21\n",
      "    ‚Ä¢ RoBERTa                                    ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.20\n",
      "    ‚Ä¢ 365 Data Science                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Deep Learning with TensorFlow 2            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Oracle Cloud Infrastructure 2025 Certified Generative AI Professional ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Introduction to Networks                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "\n",
      "  [Langue / Language]\n",
      "    ‚Ä¢ Anglais                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 0.89\n",
      "    ‚Ä¢ Arabe                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 0.87\n",
      "    ‚Ä¢ Fran√ßais                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 0.83\n",
      "    ‚Ä¢ Pr√©sident                                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.54\n",
      "    ‚Ä¢ Interm√©diaire                              ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.47\n",
      "    ‚Ä¢ League of Legends                          ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.39\n",
      "    ‚Ä¢ Langue maternelle                          ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.27\n",
      "    ‚Ä¢ Membre principal                           ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.26\n",
      "\n",
      "  [Entreprise / Company]\n",
      "    ‚Ä¢ Google Developer Group                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.78\n",
      "    ‚Ä¢ Chess Club                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.76\n",
      "    ‚Ä¢ YaneCode                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.75\n",
      "    ‚Ä¢ Banque Centrale Populaire                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.75\n",
      "    ‚Ä¢ Campus Universiapolis                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.59\n",
      "    ‚Ä¢ AZUL-AI                                    ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.50\n",
      "    ‚Ä¢ GDG                                        ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.48\n",
      "    ‚Ä¢ Club Nakama (Culture asiatique)            ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.44\n",
      "    ‚Ä¢ Universit√© Cadi Ayyad                      ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.42\n",
      "    ‚Ä¢ ENSIASD                                    ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.40\n",
      "    ‚Ä¢ EST                                        ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.35\n",
      "    ‚Ä¢ SmartCourseQA                              ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.33\n",
      "    ‚Ä¢ LinkedIn                                   ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.33\n",
      "    ‚Ä¢ Oracle                                     ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.30\n",
      "    ‚Ä¢ Flask                                      ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.30\n",
      "    ‚Ä¢ √âcole Sup√©rieure de Technologie            ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.28\n",
      "    ‚Ä¢ MySQL                                      ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.25\n",
      "\n",
      "  Total entities : 114\n",
      "  Categories filled: 7/9\n",
      "\n",
      "=================================================================\n",
      "EXTRACTED ENTITIES (EN)\n",
      "=================================================================\n",
      "\n",
      "  [Hard Skill]\n",
      "    ‚Ä¢ Member                                     ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.27\n",
      "    ‚Ä¢ Python                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ TensorFlow                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ PyTorch                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Scikit-learn                               ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Pandas                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ NumPy                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Matplotlib                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Seaborn                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ NLP                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Power BI                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Flask                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Django                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Laravel                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Git                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ GitHub                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Docker                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Linux                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ MySQL                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ SQLite                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ PostgreSQL                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ MongoDB                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Hadoop                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ MapReduce                                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Java                                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ SQL                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ FAISS                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ BM25                                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Machine Learning                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Deep Learning                              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ CamemBERT                                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Random Forest                              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ SentenceTransformers                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ RoBERTa                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Selenium                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ JavaScript                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Chart.js                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ n8n                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Gemini LLM                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ GPT-4o-mini                                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ RAG                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "\n",
      "  [Soft Skill]\n",
      "    ‚Ä¢ President                                  ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.42\n",
      "    ‚Ä¢ Data Science Intern                        ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.30\n",
      "\n",
      "  [Education]\n",
      "    ‚Ä¢ Pandas                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.73\n",
      "    ‚Ä¢ NumPy                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 0.63\n",
      "    ‚Ä¢ Scikit-learn                               ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 0.62\n",
      "    ‚Ä¢ PostgreSQL                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.57\n",
      "    ‚Ä¢ Flask                                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.56\n",
      "    ‚Ä¢ Laravel                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.54\n",
      "    ‚Ä¢ Gemini LLM                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.54\n",
      "    ‚Ä¢ Power BI                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.53\n",
      "    ‚Ä¢ TensorFlow                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.52\n",
      "    ‚Ä¢ GitHub                                     ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.49\n",
      "    ‚Ä¢ National School of Artificial Intelligence and Data Science ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.44\n",
      "    ‚Ä¢ CamemBERT + Random Forest                  ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.43\n",
      "    ‚Ä¢ Engineering Degree in Data Science, Big Data & Artificial Intelligence ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.42\n",
      "    ‚Ä¢ Engineering Student in Data Science & Artificial Intelligence ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.37\n",
      "    ‚Ä¢ League of Legends                          ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.32\n",
      "    ‚Ä¢ LinkedIn                                   ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.32\n",
      "    ‚Ä¢ API                                        ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.28\n",
      "    ‚Ä¢ University Diploma of Technology           ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.25\n",
      "    ‚Ä¢ JavaScript                                 ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.20\n",
      "    ‚Ä¢ Portfolio                                  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.20\n",
      "\n",
      "  [Project]\n",
      "    ‚Ä¢ Laravel                                    ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.33\n",
      "    ‚Ä¢ Gemini LLM                                 ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.32\n",
      "    ‚Ä¢ Flask                                      ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.31\n",
      "    ‚Ä¢ RAG                                        ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.29\n",
      "    ‚Ä¢ GPT-4o-mini                                ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.29\n",
      "    ‚Ä¢ BM25                                       ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.25\n",
      "    ‚Ä¢ FAISS                                      ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.24\n",
      "    ‚Ä¢ SentenceTransformers                       ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.24\n",
      "    ‚Ä¢ Scikit-learn                               ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.22\n",
      "    ‚Ä¢ Django                                     ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.21\n",
      "\n",
      "  [Certification]\n",
      "    ‚Ä¢ CCNAv7                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.74\n",
      "    ‚Ä¢ Certified Generative AI                    ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.24\n",
      "    ‚Ä¢ JavaScript API                             ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.23\n",
      "    ‚Ä¢ Power BI                                   ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.23\n",
      "    ‚Ä¢ AI-based recommendation system             ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.23\n",
      "    ‚Ä¢ Chart.js                                   ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.22\n",
      "    ‚Ä¢ 365 Data Science                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Deep Learning with TensorFlow 2            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Oracle Cloud Infrastructure 2025           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "    ‚Ä¢ Introduction to Networks                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë 0.90\n",
      "\n",
      "  [Language]\n",
      "    ‚Ä¢ English                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 0.87\n",
      "    ‚Ä¢ Arabic                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.78\n",
      "    ‚Ä¢ French                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.78\n",
      "    ‚Ä¢ performance metrics                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.52\n",
      "    ‚Ä¢ player statistics                          ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.37\n",
      "    ‚Ä¢ Core Member                                ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.32\n",
      "    ‚Ä¢ EXTRACURRICULAR ACTIVITIES                 ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.30\n",
      "    ‚Ä¢ President                                  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.28\n",
      "    ‚Ä¢ Native                                     ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.25\n",
      "\n",
      "  [Company]\n",
      "    ‚Ä¢ YaneCode                                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.72\n",
      "    ‚Ä¢ Banque Centrale Populaire                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.72\n",
      "    ‚Ä¢ Google Developer Group                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 0.69\n",
      "    ‚Ä¢ Chess Club                                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 0.65\n",
      "    ‚Ä¢ AZUL-AI                                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.58\n",
      "    ‚Ä¢ Amazon                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.56\n",
      "    ‚Ä¢ Nakama Club                                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.54\n",
      "    ‚Ä¢ GDG                                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.53\n",
      "    ‚Ä¢ Universiapolis Campus                      ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.48\n",
      "    ‚Ä¢ SmartCourseQA                              ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.46\n",
      "    ‚Ä¢ Asian Culture Club                         ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.44\n",
      "    ‚Ä¢ Cadi Ayyad University                      ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.38\n",
      "    ‚Ä¢ Oracle                                     ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.32\n",
      "    ‚Ä¢ EST                                        ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.23\n",
      "    ‚Ä¢ ENSIASD                                    ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.21\n",
      "\n",
      "  Total entities : 107\n",
      "  Categories filled: 7/9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================\n",
    "# Soft skill keywords to boost\n",
    "# ==============================\n",
    "soft_skills_keywords = [\n",
    "    \"Leadership\", \"Teamwork\", \"Communication\", \"Problem-solving\",\n",
    "    \"Adaptability\", \"Creativity\", \"Critical thinking\", \"Time management\"\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# Extract (threshold=0.2 for high recall; model+preprocessing handle precision)\n",
    "# ==============================\n",
    "results_fr = extract_entities(text_fr, labels_fr, model, threshold=0.2)\n",
    "results_en = extract_entities(text_en, labels_en, model, threshold=0.2)\n",
    "\n",
    "# ==============================\n",
    "# Merge: dedup + split comma-spans + NMS substring filter\n",
    "# ==============================\n",
    "results_fr = merge_entities(results_fr, min_length=2)\n",
    "results_en = merge_entities(results_en, min_length=2)\n",
    "\n",
    "# ==============================\n",
    "# Boost: soft skills, hard skills, certifications\n",
    "# ==============================\n",
    "# Preprocess text once (for keyword scanning)\n",
    "text_fr_clean = preprocess_text(text_fr)\n",
    "text_en_clean = preprocess_text(text_en)\n",
    "\n",
    "results_fr = boost_soft_skills(results_fr, text_fr_clean, soft_skills_keywords, lang=\"FR\")\n",
    "results_en = boost_soft_skills(results_en, text_en_clean, soft_skills_keywords, lang=\"EN\")\n",
    "\n",
    "results_fr = boost_hard_skills(results_fr, text_fr_clean, HARD_SKILLS_KEYWORDS)\n",
    "results_en = boost_hard_skills(results_en, text_en_clean, HARD_SKILLS_KEYWORDS)\n",
    "\n",
    "results_fr = boost_certifications(results_fr, text_fr_clean, CERT_KEYWORDS)\n",
    "results_en = boost_certifications(results_en, text_en_clean, CERT_KEYWORDS)\n",
    "\n",
    "# ==============================\n",
    "# Display\n",
    "# ==============================\n",
    "display_results(results_fr, labels_fr, lang=\"FR\")\n",
    "display_results(results_en, labels_en, lang=\"EN\")\n",
    "\n",
    "# ==============================\n",
    "# Side-by-side comparison (uncomment to use)\n",
    "# ==============================\n",
    "# df_comparison = compare_results(results_fr, results_en, labels_fr, labels_en)\n",
    "# print(\"\\n\" + \"=\"*65)\n",
    "# print(\"SIDE-BY-SIDE COMPARISON\")\n",
    "# print(\"=\"*65)\n",
    "# print(df_comparison.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f685b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTITY COUNT PER CATEGORY ===\n",
      "\n",
      "Category                                         FR    EN\n",
      "----------------------------------------------------------\n",
      "Hard Skill                                       42    41\n",
      "Soft Skill                                        0     2\n",
      "Education                                        18    20\n",
      "Experience                                        3     0\n",
      "Project                                          11    10\n",
      "Certification                                    15    10\n",
      "Language                                          8     9\n",
      "Extracurricular Activity                          0     0\n",
      "Company                                          17    15\n",
      "----------------------------------------------------------\n",
      "TOTAL                                           114   107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================\n",
    "# Quick stats summary\n",
    "# ==============================\n",
    "print(\"=== ENTITY COUNT PER CATEGORY ===\\n\")\n",
    "print(f\"{'Category':<45} {'FR':>5} {'EN':>5}\")\n",
    "print(\"-\" * 58)\n",
    "for fl, el in zip(labels_fr, labels_en):\n",
    "    cat = el.split(\"(\")[0].strip()\n",
    "    print(f\"{cat:<45} {len(results_fr[fl]):>5} {len(results_en[el]):>5}\")\n",
    "\n",
    "total_fr = sum(len(v) for v in results_fr.values())\n",
    "total_en = sum(len(v) for v in results_en.values())\n",
    "print(\"-\" * 58)\n",
    "print(f\"{'TOTAL':<45} {total_fr:>5} {total_en:>5}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
